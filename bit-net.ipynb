{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse,random\n",
    "from math import log10\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data import get_training_set, get_test_set\n",
    "from torch.nn.modules.module import _addindent\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "import quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1을 사용할시에\n",
    "from net.model import Net\n",
    "# model 2을 사용할시에\n",
    "#from net.model_dw import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda import\n",
    "cuda = True\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "torch.manual_seed(random.randint(1,1000))\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset import\n",
    "train_set = get_training_set(2,\"BSDS300\")\n",
    "test_set = get_test_set(2,\"BSDS300\")\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=11, batch_size=16, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=10, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_factor=2\n",
    "train=Net(upscale_factor)\n",
    "weight_name='weight1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weigh\n",
    "model=torch.load(weight_name)\n",
    "keys=model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "___\n",
    "\n",
    "```\n",
    "self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "self.conv2=nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "self.conv3=nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "__upscale_factor는 2 이다__\n",
    "\n",
    "<br><br>\n",
    "####  weight1 초기 PSNR\n",
    "\n",
    "```\n",
    "===> Avg. PSNR: 27.7404 dB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning method\n",
    "___\n",
    "\n",
    "1. Pruning을 할 수 있는 spot을 선택 \n",
    "1. 1개를 선택하여 prunging 한 후에 Net의 아키텍쳐를 바꾼다.\n",
    "1. L1 norm 을 기준으로 pruning 한다.\n",
    "1. PSNR 값을 구한다.\n",
    "1. retraining을 진행.\n",
    "1. 반복(일정 PSNR 이하 로 내려가기전까지)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def modify(net,alpha=64,beta=64,gamma=32):\n",
    "    \"\"\"\n",
    "    네트워크와 하이퍼 파라미터를 입력받아\n",
    "    네트워크를 하이퍼 파라미터에 맞게 변형한다.\n",
    "    \"\"\"\n",
    "    net.conv1 = nn.Conv2d(1, alpha, (5, 5), (1, 1), (2, 2))\n",
    "    net.conv2=nn.Conv2d(alpha, beta, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv3=nn.Conv2d(beta, gamma, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv4 = nn.Conv2d(gamma, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "    \n",
    "def PSNR(net):\n",
    "    '''\n",
    "    네트워크 를 받아서 psnr 값을 구하여 반환한다.\n",
    "    테스트 배치 만큼 수행 평균\n",
    "    '''\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target=target.cuda()\n",
    "        prediction = net(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "    return avg_psnr/len(testing_data_loader)\n",
    "\n",
    "def _train(net,epoch=50):\n",
    "    '''\n",
    "    네트워크와 에폭,학습률을 입력 받아 그에 맞게 학습시킨다.\n",
    "    '''\n",
    "    #net=nn.DataParallel(net) 이렇게 하는게 더 느리다 % time으로 확인\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(input), target)\n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n",
    "    if epoch%10 is 0:\n",
    "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "\n",
    "def rank(_list):\n",
    "    '''\n",
    "    _list를 입력받아 계산한뒤 pruning 할 (conv,weight)의 위치를 tuple로 반환한다.\n",
    "    pruning 할 layer를 고른다.\n",
    "    기준은 L2와 PSNR 을 기준으로 rank를 만든 뒤 합하여 결정한다.\n",
    "    '''\n",
    "    df=DataFrame(_list,columns=['conv','weight','psnr','L2'])\n",
    "    df['rank']=df['psnr'].rank( ascending=False,method='max')+df['L2'].rank(method='max')\n",
    "    for idx,i in enumerate(df[\"L2\"]):\n",
    "        if i == min(df[\"L2\"]):\n",
    "            print(df['conv'][idx],\"th conv's \",df['weight'][idx],\"'s layer will pruning\")\n",
    "            return(df['conv'][idx],df['weight'][idx])\n",
    "def test(net):\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            net=net.cuda()\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        prediction = net(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "\n",
    "        print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(testing_data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Avg. PSNR: 27.7372 dB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def bit_truncation(model,bits=8):\n",
    "    quant_method='linear'\n",
    "    overflow_rate=0.0\n",
    "    state_dict = deepcopy(model)\n",
    "    state_dict_quant = OrderedDict()\n",
    "    sf_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if bits >=32:\n",
    "            print(\"Ignoring {}\".format(k))\n",
    "            state_dict_quant[k] = v\n",
    "            continue\n",
    "        if quant_method == 'linear':\n",
    "            sf = bits - 1. - quant.compute_integral_part(v, overflow_rate=overflow_rate)\n",
    "            v_quant  = quant.linear_quantize(v, sf, bits=bits)\n",
    "        elif args.quant_method == 'log':\n",
    "            v_quant = quant.log_minmax_quantize(v, bits=bits)\n",
    "        elif args.quant_method == 'minmax':\n",
    "            v_quant = quant.min_max_quantize(v, bits=bits)\n",
    "        else:\n",
    "            v_quant = quant.tanh_quantize(v, bits=bits)\n",
    "        state_dict_quant[k] = v_quant\n",
    "    return state_dict_quant\n",
    "state_dict_quant=bit_truncation(model,12)\n",
    "\n",
    "train.load_state_dict(state_dict_quant)\n",
    "test(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_items([('conv1.weight', \n",
       "(0 ,0 ,.,.) = \n",
       " 0.049804687500000000000000000000 -0.106445312500000000000000000000 -0.029296875000000000000000000000 -0.130859375000000000000000000000 -0.081054687500000000000000000000\n",
       " -0.074218750000000000000000000000 -0.042968750000000000000000000000 0.059570312500000000000000000000 0.227539062500000000000000000000 0.126953125000000000000000000000\n",
       " 0.066406250000000000000000000000 0.082031250000000000000000000000 0.047851562500000000000000000000 -0.095703125000000000000000000000 -0.187500000000000000000000000000\n",
       " -0.127929687500000000000000000000 0.064453125000000000000000000000 -0.174804687500000000000000000000 0.153320312500000000000000000000 0.152343750000000000000000000000\n",
       " -0.126953125000000000000000000000 -0.008789062500000000000000000000 0.469726562500000000000000000000 -0.071289062500000000000000000000 -0.168945312500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " 0.028320312500000000000000000000 0.024414062500000000000000000000 0.077148437500000000000000000000 0.011718750000000000000000000000 0.146484375000000000000000000000\n",
       " 0.089843750000000000000000000000 -0.114257812500000000000000000000 -0.208007812500000000000000000000 -0.125976562500000000000000000000 -0.156250000000000000000000000000\n",
       " -0.022460937500000000000000000000 0.059570312500000000000000000000 0.169921875000000000000000000000 -0.783203125000000000000000000000 0.218750000000000000000000000000\n",
       " 0.055664062500000000000000000000 0.354492187500000000000000000000 0.166015625000000000000000000000 -0.252929687500000000000000000000 -0.132812500000000000000000000000\n",
       " -0.055664062500000000000000000000 0.185546875000000000000000000000 -0.063476562500000000000000000000 0.009765625000000000000000000000 0.045898437500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " -0.124023437500000000000000000000 -0.251953125000000000000000000000 0.218750000000000000000000000000 0.103515625000000000000000000000 -0.009765625000000000000000000000\n",
       " -0.144531250000000000000000000000 0.065429687500000000000000000000 0.003906250000000000000000000000 0.131835937500000000000000000000 0.225585937500000000000000000000\n",
       " -0.087890625000000000000000000000 0.193359375000000000000000000000 0.026367187500000000000000000000 -0.119140625000000000000000000000 0.192382812500000000000000000000\n",
       " 0.011718750000000000000000000000 0.148437500000000000000000000000 0.017578125000000000000000000000 0.213867187500000000000000000000 -0.174804687500000000000000000000\n",
       " 0.026367187500000000000000000000 0.022460937500000000000000000000 0.069335937500000000000000000000 -0.073242187500000000000000000000 0.044921875000000000000000000000\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(61,0 ,.,.) = \n",
       " 0.606445312500000000000000000000 -0.059570312500000000000000000000 -0.057617187500000000000000000000 -0.260742187500000000000000000000 -0.064453125000000000000000000000\n",
       " 0.077148437500000000000000000000 -0.119140625000000000000000000000 0.008789062500000000000000000000 0.014648437500000000000000000000 0.229492187500000000000000000000\n",
       " -0.329101562500000000000000000000 -0.107421875000000000000000000000 0.147460937500000000000000000000 -0.078125000000000000000000000000 -0.131835937500000000000000000000\n",
       " 0.069335937500000000000000000000 0.035156250000000000000000000000 0.011718750000000000000000000000 -0.128906250000000000000000000000 -0.172851562500000000000000000000\n",
       " 0.097656250000000000000000000000 0.042968750000000000000000000000 -0.048828125000000000000000000000 -0.161132812500000000000000000000 0.079101562500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(62,0 ,.,.) = \n",
       " -0.031250000000000000000000000000 0.131835937500000000000000000000 0.037109375000000000000000000000 0.162109375000000000000000000000 -0.106445312500000000000000000000\n",
       " 0.279296875000000000000000000000 -0.208984375000000000000000000000 0.009765625000000000000000000000 -0.380859375000000000000000000000 0.342773437500000000000000000000\n",
       " -0.039062500000000000000000000000 -0.020507812500000000000000000000 0.126953125000000000000000000000 0.055664062500000000000000000000 0.115234375000000000000000000000\n",
       " -0.183593750000000000000000000000 0.344726562500000000000000000000 -0.076171875000000000000000000000 0.466796875000000000000000000000 -0.367187500000000000000000000000\n",
       " 0.083007812500000000000000000000 -0.119140625000000000000000000000 0.174804687500000000000000000000 -0.125976562500000000000000000000 -0.178710937500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(63,0 ,.,.) = \n",
       " -0.261718750000000000000000000000 0.088867187500000000000000000000 0.080078125000000000000000000000 -0.032226562500000000000000000000 -0.066406250000000000000000000000\n",
       " -0.017578125000000000000000000000 0.073242187500000000000000000000 0.432617187500000000000000000000 -0.170898437500000000000000000000 -0.073242187500000000000000000000\n",
       " 0.059570312500000000000000000000 0.129882812500000000000000000000 0.370117187500000000000000000000 -0.325195312500000000000000000000 0.120117187500000000000000000000\n",
       " 0.086914062500000000000000000000 -0.200195312500000000000000000000 -0.164062500000000000000000000000 -0.279296875000000000000000000000 0.172851562500000000000000000000\n",
       " -0.019531250000000000000000000000 0.155273437500000000000000000000 0.291015625000000000000000000000 -0.105468750000000000000000000000 -0.020507812500000000000000000000\n",
       "[torch.cuda.FloatTensor of size 64x1x5x5 (GPU 0)]\n",
       "), ('conv1.bias', \n",
       "0.094360351562500000000000000000\n",
       "-0.043701171875000000000000000000\n",
       "-0.005371093750000000000000000000\n",
       "0.075561523437500000000000000000\n",
       "0.054443359375000000000000000000\n",
       "0.029174804687500000000000000000\n",
       "0.094726562500000000000000000000\n",
       "0.082519531250000000000000000000\n",
       "0.007568359375000000000000000000\n",
       "-0.093261718750000000000000000000\n",
       "0.035278320312500000000000000000\n",
       "0.170776367187500000000000000000\n",
       "-0.111938476562500000000000000000\n",
       "0.178710937500000000000000000000\n",
       "0.143798828125000000000000000000\n",
       "0.134643554687500000000000000000\n",
       "0.007568359375000000000000000000\n",
       "0.084350585937500000000000000000\n",
       "0.163452148437500000000000000000\n",
       "0.126220703125000000000000000000\n",
       "0.053955078125000000000000000000\n",
       "0.001464843750000000000000000000\n",
       "-0.114379882812500000000000000000\n",
       "0.004760742187500000000000000000\n",
       "0.091552734375000000000000000000\n",
       "-0.139404296875000000000000000000\n",
       "-0.000366210937500000000000000000\n",
       "-0.057128906250000000000000000000\n",
       "0.024291992187500000000000000000\n",
       "-0.012939453125000000000000000000\n",
       "-0.166015625000000000000000000000\n",
       "-0.040161132812500000000000000000\n",
       "-0.043823242187500000000000000000\n",
       "-0.023437500000000000000000000000\n",
       "0.129272460937500000000000000000\n",
       "0.107788085937500000000000000000\n",
       "-0.088989257812500000000000000000\n",
       "-0.064575195312500000000000000000\n",
       "-0.037231445312500000000000000000\n",
       "-0.050170898437500000000000000000\n",
       "0.186645507812500000000000000000\n",
       "-0.033325195312500000000000000000\n",
       "0.117553710937500000000000000000\n",
       "-0.040405273437500000000000000000\n",
       "0.020019531250000000000000000000\n",
       "0.105102539062500000000000000000\n",
       "-0.062988281250000000000000000000\n",
       "-0.002441406250000000000000000000\n",
       "0.012573242187500000000000000000\n",
       "0.055419921875000000000000000000\n",
       "0.022460937500000000000000000000\n",
       "-0.146362304687500000000000000000\n",
       "0.045043945312500000000000000000\n",
       "-0.061401367187500000000000000000\n",
       "0.030883789062500000000000000000\n",
       "-0.007446289062500000000000000000\n",
       "0.152343750000000000000000000000\n",
       "0.180786132812500000000000000000\n",
       "0.112304687500000000000000000000\n",
       "-0.242309570312500000000000000000\n",
       "-0.095947265625000000000000000000\n",
       "0.090454101562500000000000000000\n",
       "-0.161865234375000000000000000000\n",
       "-0.168701171875000000000000000000\n",
       "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
       "), ('conv2.weight', \n",
       "(0 ,0 ,.,.) = \n",
       " 0.083984375000000000000000000000 0.068359375000000000000000000000 -0.091796875000000000000000000000\n",
       " -0.007812500000000000000000000000 0.035156250000000000000000000000 -0.001953125000000000000000000000\n",
       " 0.115234375000000000000000000000 -0.031250000000000000000000000000 -0.056640625000000000000000000000\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -0.126953125000000000000000000000 -0.046875000000000000000000000000 0.103515625000000000000000000000\n",
       " 0.179687500000000000000000000000 0.103515625000000000000000000000 0.197265625000000000000000000000\n",
       " 0.003906250000000000000000000000 -0.064453125000000000000000000000 -0.033203125000000000000000000000\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -0.103515625000000000000000000000 -0.005859375000000000000000000000 -0.078125000000000000000000000000\n",
       " -0.064453125000000000000000000000 0.025390625000000000000000000000 0.044921875000000000000000000000\n",
       " -0.003906250000000000000000000000 -0.060546875000000000000000000000 0.025390625000000000000000000000\n",
       "   ...\n",
       "\n",
       "(0 ,61,.,.) = \n",
       " -0.072265625000000000000000000000 0.091796875000000000000000000000 0.007812500000000000000000000000\n",
       " -0.046875000000000000000000000000 0.062500000000000000000000000000 -0.048828125000000000000000000000\n",
       " -0.175781250000000000000000000000 0.117187500000000000000000000000 -0.072265625000000000000000000000\n",
       "\n",
       "(0 ,62,.,.) = \n",
       " 0.123046875000000000000000000000 -0.132812500000000000000000000000 0.281250000000000000000000000000\n",
       " 0.003906250000000000000000000000 -0.074218750000000000000000000000 0.150390625000000000000000000000\n",
       " -0.130859375000000000000000000000 0.095703125000000000000000000000 -0.058593750000000000000000000000\n",
       "\n",
       "(0 ,63,.,.) = \n",
       " -0.177734375000000000000000000000 -0.037109375000000000000000000000 -0.175781250000000000000000000000\n",
       " -0.203125000000000000000000000000 0.173828125000000000000000000000 -0.357421875000000000000000000000\n",
       " -0.033203125000000000000000000000 0.117187500000000000000000000000 -0.117187500000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -0.031250000000000000000000000000 0.005859375000000000000000000000 -0.078125000000000000000000000000\n",
       " 0.101562500000000000000000000000 0.015625000000000000000000000000 -0.048828125000000000000000000000\n",
       " -0.052734375000000000000000000000 0.060546875000000000000000000000 -0.085937500000000000000000000000\n",
       "\n",
       "(1 ,1 ,.,.) = \n",
       " -0.039062500000000000000000000000 -0.089843750000000000000000000000 0.205078125000000000000000000000\n",
       " -0.123046875000000000000000000000 0.015625000000000000000000000000 -0.183593750000000000000000000000\n",
       " 0.220703125000000000000000000000 0.011718750000000000000000000000 -0.009765625000000000000000000000\n",
       "\n",
       "(1 ,2 ,.,.) = \n",
       " 0.046875000000000000000000000000 -0.023437500000000000000000000000 0.005859375000000000000000000000\n",
       " -0.029296875000000000000000000000 0.048828125000000000000000000000 0.029296875000000000000000000000\n",
       " -0.031250000000000000000000000000 -0.013671875000000000000000000000 0.015625000000000000000000000000\n",
       "   ...\n",
       "\n",
       "(1 ,61,.,.) = \n",
       " -0.044921875000000000000000000000 -0.054687500000000000000000000000 0.109375000000000000000000000000\n",
       " 0.095703125000000000000000000000 0.093750000000000000000000000000 -0.042968750000000000000000000000\n",
       " 0.001953125000000000000000000000 -0.015625000000000000000000000000 0.031250000000000000000000000000\n",
       "\n",
       "(1 ,62,.,.) = \n",
       " 0.048828125000000000000000000000 -0.009765625000000000000000000000 0.001953125000000000000000000000\n",
       " 0.126953125000000000000000000000 -0.001953125000000000000000000000 0.093750000000000000000000000000\n",
       " -0.019531250000000000000000000000 -0.039062500000000000000000000000 -0.085937500000000000000000000000\n",
       "\n",
       "(1 ,63,.,.) = \n",
       " 0.019531250000000000000000000000 0.058593750000000000000000000000 0.013671875000000000000000000000\n",
       " 0.107421875000000000000000000000 0.050781250000000000000000000000 0.023437500000000000000000000000\n",
       " 0.091796875000000000000000000000 -0.041015625000000000000000000000 0.123046875000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " 0.003906250000000000000000000000 -0.003906250000000000000000000000 0.042968750000000000000000000000\n",
       " 0.007812500000000000000000000000 0.087890625000000000000000000000 0.091796875000000000000000000000\n",
       " 0.115234375000000000000000000000 0.037109375000000000000000000000 0.013671875000000000000000000000\n",
       "\n",
       "(2 ,1 ,.,.) = \n",
       " -0.320312500000000000000000000000 0.076171875000000000000000000000 -0.009765625000000000000000000000\n",
       " -0.060546875000000000000000000000 0.068359375000000000000000000000 -0.050781250000000000000000000000\n",
       " 0.025390625000000000000000000000 0.041015625000000000000000000000 -0.037109375000000000000000000000\n",
       "\n",
       "(2 ,2 ,.,.) = \n",
       " 0.019531250000000000000000000000 -0.015625000000000000000000000000 -0.005859375000000000000000000000\n",
       " 0.099609375000000000000000000000 -0.099609375000000000000000000000 -0.128906250000000000000000000000\n",
       " 0.017578125000000000000000000000 0.011718750000000000000000000000 -0.064453125000000000000000000000\n",
       "   ...\n",
       "\n",
       "(2 ,61,.,.) = \n",
       " -0.076171875000000000000000000000 0.074218750000000000000000000000 0.019531250000000000000000000000\n",
       " -0.041015625000000000000000000000 -0.023437500000000000000000000000 -0.072265625000000000000000000000\n",
       " -0.027343750000000000000000000000 0.029296875000000000000000000000 -0.044921875000000000000000000000\n",
       "\n",
       "(2 ,62,.,.) = \n",
       " -0.003906250000000000000000000000 0.003906250000000000000000000000 0.027343750000000000000000000000\n",
       " 0.039062500000000000000000000000 -0.041015625000000000000000000000 0.025390625000000000000000000000\n",
       " -0.046875000000000000000000000000 0.021484375000000000000000000000 0.072265625000000000000000000000\n",
       "\n",
       "(2 ,63,.,.) = \n",
       " -0.021484375000000000000000000000 -0.070312500000000000000000000000 0.056640625000000000000000000000\n",
       " -0.054687500000000000000000000000 -0.009765625000000000000000000000 -0.017578125000000000000000000000\n",
       " -0.021484375000000000000000000000 -0.025390625000000000000000000000 -0.013671875000000000000000000000\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(61,0 ,.,.) = \n",
       " 0.068359375000000000000000000000 -0.101562500000000000000000000000 0.029296875000000000000000000000\n",
       " 0.058593750000000000000000000000 0.115234375000000000000000000000 0.005859375000000000000000000000\n",
       " 0.042968750000000000000000000000 -0.023437500000000000000000000000 -0.017578125000000000000000000000\n",
       "\n",
       "(61,1 ,.,.) = \n",
       " -0.078125000000000000000000000000 0.064453125000000000000000000000 0.056640625000000000000000000000\n",
       " -0.039062500000000000000000000000 0.089843750000000000000000000000 0.005859375000000000000000000000\n",
       " -0.083984375000000000000000000000 -0.105468750000000000000000000000 0.189453125000000000000000000000\n",
       "\n",
       "(61,2 ,.,.) = \n",
       " -0.023437500000000000000000000000 0.076171875000000000000000000000 0.025390625000000000000000000000\n",
       " 0.044921875000000000000000000000 0.062500000000000000000000000000 0.093750000000000000000000000000\n",
       " 0.111328125000000000000000000000 0.054687500000000000000000000000 0.031250000000000000000000000000\n",
       "   ...\n",
       "\n",
       "(61,61,.,.) = \n",
       " 0.095703125000000000000000000000 -0.039062500000000000000000000000 -0.058593750000000000000000000000\n",
       " -0.013671875000000000000000000000 -0.039062500000000000000000000000 0.015625000000000000000000000000\n",
       " 0.003906250000000000000000000000 0.021484375000000000000000000000 -0.052734375000000000000000000000\n",
       "\n",
       "(61,62,.,.) = \n",
       " -0.029296875000000000000000000000 0.000000000000000000000000000000 0.062500000000000000000000000000\n",
       " 0.011718750000000000000000000000 0.011718750000000000000000000000 0.035156250000000000000000000000\n",
       " 0.056640625000000000000000000000 -0.058593750000000000000000000000 -0.035156250000000000000000000000\n",
       "\n",
       "(61,63,.,.) = \n",
       " -0.058593750000000000000000000000 0.001953125000000000000000000000 -0.093750000000000000000000000000\n",
       " 0.046875000000000000000000000000 0.048828125000000000000000000000 0.042968750000000000000000000000\n",
       " -0.023437500000000000000000000000 0.101562500000000000000000000000 -0.035156250000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(62,0 ,.,.) = \n",
       " -0.072265625000000000000000000000 0.062500000000000000000000000000 -0.009765625000000000000000000000\n",
       " 0.113281250000000000000000000000 -0.060546875000000000000000000000 0.101562500000000000000000000000\n",
       " 0.029296875000000000000000000000 0.093750000000000000000000000000 -0.138671875000000000000000000000\n",
       "\n",
       "(62,1 ,.,.) = \n",
       " -0.119140625000000000000000000000 -0.005859375000000000000000000000 0.025390625000000000000000000000\n",
       " -0.001953125000000000000000000000 0.070312500000000000000000000000 0.039062500000000000000000000000\n",
       " 0.046875000000000000000000000000 -0.025390625000000000000000000000 -0.025390625000000000000000000000\n",
       "\n",
       "(62,2 ,.,.) = \n",
       " 0.011718750000000000000000000000 0.062500000000000000000000000000 -0.046875000000000000000000000000\n",
       " -0.052734375000000000000000000000 0.033203125000000000000000000000 -0.050781250000000000000000000000\n",
       " 0.052734375000000000000000000000 -0.042968750000000000000000000000 0.058593750000000000000000000000\n",
       "   ...\n",
       "\n",
       "(62,61,.,.) = \n",
       " 0.005859375000000000000000000000 -0.029296875000000000000000000000 0.046875000000000000000000000000\n",
       " 0.103515625000000000000000000000 -0.039062500000000000000000000000 -0.017578125000000000000000000000\n",
       " -0.048828125000000000000000000000 0.035156250000000000000000000000 0.046875000000000000000000000000\n",
       "\n",
       "(62,62,.,.) = \n",
       " 0.037109375000000000000000000000 -0.039062500000000000000000000000 -0.066406250000000000000000000000\n",
       " -0.027343750000000000000000000000 -0.082031250000000000000000000000 -0.078125000000000000000000000000\n",
       " -0.035156250000000000000000000000 -0.062500000000000000000000000000 0.091796875000000000000000000000\n",
       "\n",
       "(62,63,.,.) = \n",
       " -0.109375000000000000000000000000 -0.035156250000000000000000000000 0.060546875000000000000000000000\n",
       " 0.068359375000000000000000000000 0.000000000000000000000000000000 0.035156250000000000000000000000\n",
       " 0.044921875000000000000000000000 0.042968750000000000000000000000 -0.013671875000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(63,0 ,.,.) = \n",
       " -0.048828125000000000000000000000 -0.021484375000000000000000000000 -0.019531250000000000000000000000\n",
       " -0.011718750000000000000000000000 0.031250000000000000000000000000 0.035156250000000000000000000000\n",
       " 0.048828125000000000000000000000 0.013671875000000000000000000000 0.050781250000000000000000000000\n",
       "\n",
       "(63,1 ,.,.) = \n",
       " -0.041015625000000000000000000000 0.021484375000000000000000000000 -0.039062500000000000000000000000\n",
       " -0.130859375000000000000000000000 -0.082031250000000000000000000000 -0.132812500000000000000000000000\n",
       " 0.015625000000000000000000000000 -0.144531250000000000000000000000 -0.060546875000000000000000000000\n",
       "\n",
       "(63,2 ,.,.) = \n",
       " -0.031250000000000000000000000000 -0.037109375000000000000000000000 0.087890625000000000000000000000\n",
       " 0.056640625000000000000000000000 0.007812500000000000000000000000 -0.083984375000000000000000000000\n",
       " -0.041015625000000000000000000000 -0.078125000000000000000000000000 0.041015625000000000000000000000\n",
       "   ...\n",
       "\n",
       "(63,61,.,.) = \n",
       " 0.056640625000000000000000000000 0.005859375000000000000000000000 0.035156250000000000000000000000\n",
       " -0.031250000000000000000000000000 0.070312500000000000000000000000 -0.017578125000000000000000000000\n",
       " -0.017578125000000000000000000000 -0.009765625000000000000000000000 0.025390625000000000000000000000\n",
       "\n",
       "(63,62,.,.) = \n",
       " -0.001953125000000000000000000000 -0.027343750000000000000000000000 0.039062500000000000000000000000\n",
       " -0.044921875000000000000000000000 -0.009765625000000000000000000000 -0.029296875000000000000000000000\n",
       " -0.015625000000000000000000000000 0.023437500000000000000000000000 0.107421875000000000000000000000\n",
       "\n",
       "(63,63,.,.) = \n",
       " -0.044921875000000000000000000000 0.023437500000000000000000000000 -0.011718750000000000000000000000\n",
       " 0.042968750000000000000000000000 0.066406250000000000000000000000 0.091796875000000000000000000000\n",
       " 0.015625000000000000000000000000 0.021484375000000000000000000000 -0.007812500000000000000000000000\n",
       "[torch.cuda.FloatTensor of size 64x64x3x3 (GPU 0)]\n",
       "), ('conv2.bias', \n",
       "0.004943847656250000000000000000\n",
       "0.020019531250000000000000000000\n",
       "-0.021789550781250000000000000000\n",
       "-0.044372558593750000000000000000\n",
       "-0.016845703125000000000000000000\n",
       "0.016174316406250000000000000000\n",
       "-0.100463867187500000000000000000\n",
       "-0.054138183593750000000000000000\n",
       "-0.056579589843750000000000000000\n",
       "-0.017395019531250000000000000000\n",
       "-0.040222167968750000000000000000\n",
       "-0.032836914062500000000000000000\n",
       "-0.016601562500000000000000000000\n",
       "0.012512207031250000000000000000\n",
       "-0.007995605468750000000000000000\n",
       "0.061889648437500000000000000000\n",
       "-0.014892578125000000000000000000\n",
       "-0.000244140625000000000000000000\n",
       "-0.006042480468750000000000000000\n",
       "0.023742675781250000000000000000\n",
       "0.007568359375000000000000000000\n",
       "-0.049743652343750000000000000000\n",
       "-0.041442871093750000000000000000\n",
       "-0.025451660156250000000000000000\n",
       "-0.028991699218750000000000000000\n",
       "0.009826660156250000000000000000\n",
       "0.035278320312500000000000000000\n",
       "0.006591796875000000000000000000\n",
       "-0.028259277343750000000000000000\n",
       "-0.014099121093750000000000000000\n",
       "0.032104492187500000000000000000\n",
       "-0.029663085937500000000000000000\n",
       "-0.038757324218750000000000000000\n",
       "0.037963867187500000000000000000\n",
       "0.012817382812500000000000000000\n",
       "0.002197265625000000000000000000\n",
       "-0.058105468750000000000000000000\n",
       "-0.008728027343750000000000000000\n",
       "0.025512695312500000000000000000\n",
       "0.082824707031250000000000000000\n",
       "0.021057128906250000000000000000\n",
       "0.037353515625000000000000000000\n",
       "0.034301757812500000000000000000\n",
       "0.026855468750000000000000000000\n",
       "0.016601562500000000000000000000\n",
       "-0.010131835937500000000000000000\n",
       "-0.004211425781250000000000000000\n",
       "0.039306640625000000000000000000\n",
       "-0.029479980468750000000000000000\n",
       "0.025573730468750000000000000000\n",
       "0.000976562500000000000000000000\n",
       "0.031555175781250000000000000000\n",
       "0.026550292968750000000000000000\n",
       "-0.041320800781250000000000000000\n",
       "-0.005004882812500000000000000000\n",
       "-0.062744140625000000000000000000\n",
       "0.010314941406250000000000000000\n",
       "0.026611328125000000000000000000\n",
       "0.020629882812500000000000000000\n",
       "-0.013549804687500000000000000000\n",
       "-0.039672851562500000000000000000\n",
       "0.044677734375000000000000000000\n",
       "0.024536132812500000000000000000\n",
       "-0.020385742187500000000000000000\n",
       "[torch.cuda.FloatTensor of size 64 (GPU 0)]\n",
       "), ('conv3.weight', \n",
       "(0 ,0 ,.,.) = \n",
       " -0.062500000000000000000000000000 -0.116210937500000000000000000000 0.126953125000000000000000000000\n",
       " -0.175781250000000000000000000000 -0.093750000000000000000000000000 -0.005859375000000000000000000000\n",
       " 0.031250000000000000000000000000 0.047851562500000000000000000000 0.000976562500000000000000000000\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -0.041015625000000000000000000000 -0.075195312500000000000000000000 0.249023437500000000000000000000\n",
       " 0.000976562500000000000000000000 0.025390625000000000000000000000 0.078125000000000000000000000000\n",
       " 0.112304687500000000000000000000 -0.074218750000000000000000000000 -0.219726562500000000000000000000\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -0.093750000000000000000000000000 0.051757812500000000000000000000 -0.010742187500000000000000000000\n",
       " -0.027343750000000000000000000000 0.051757812500000000000000000000 -0.065429687500000000000000000000\n",
       " -0.082031250000000000000000000000 0.043945312500000000000000000000 0.041015625000000000000000000000\n",
       "   ...\n",
       "\n",
       "(0 ,61,.,.) = \n",
       " -0.042968750000000000000000000000 0.005859375000000000000000000000 -0.083007812500000000000000000000\n",
       " 0.095703125000000000000000000000 0.080078125000000000000000000000 0.005859375000000000000000000000\n",
       " 0.043945312500000000000000000000 -0.003906250000000000000000000000 -0.037109375000000000000000000000\n",
       "\n",
       "(0 ,62,.,.) = \n",
       " 0.005859375000000000000000000000 -0.033203125000000000000000000000 0.026367187500000000000000000000\n",
       " 0.055664062500000000000000000000 -0.025390625000000000000000000000 -0.060546875000000000000000000000\n",
       " -0.058593750000000000000000000000 -0.046875000000000000000000000000 -0.018554687500000000000000000000\n",
       "\n",
       "(0 ,63,.,.) = \n",
       " -0.013671875000000000000000000000 0.070312500000000000000000000000 0.013671875000000000000000000000\n",
       " -0.099609375000000000000000000000 0.060546875000000000000000000000 -0.026367187500000000000000000000\n",
       " 0.003906250000000000000000000000 0.050781250000000000000000000000 -0.088867187500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -0.004882812500000000000000000000 0.015625000000000000000000000000 0.082031250000000000000000000000\n",
       " -0.061523437500000000000000000000 -0.031250000000000000000000000000 -0.024414062500000000000000000000\n",
       " 0.001953125000000000000000000000 -0.033203125000000000000000000000 -0.041015625000000000000000000000\n",
       "\n",
       "(1 ,1 ,.,.) = \n",
       " -0.002929687500000000000000000000 -0.003906250000000000000000000000 -0.136718750000000000000000000000\n",
       " -0.061523437500000000000000000000 -0.047851562500000000000000000000 0.000000000000000000000000000000\n",
       " -0.002929687500000000000000000000 -0.009765625000000000000000000000 -0.007812500000000000000000000000\n",
       "\n",
       "(1 ,2 ,.,.) = \n",
       " -0.041992187500000000000000000000 -0.016601562500000000000000000000 -0.006835937500000000000000000000\n",
       " 0.046875000000000000000000000000 0.013671875000000000000000000000 -0.038085937500000000000000000000\n",
       " 0.012695312500000000000000000000 -0.021484375000000000000000000000 0.078125000000000000000000000000\n",
       "   ...\n",
       "\n",
       "(1 ,61,.,.) = \n",
       " 0.060546875000000000000000000000 -0.062500000000000000000000000000 0.043945312500000000000000000000\n",
       " -0.027343750000000000000000000000 -0.069335937500000000000000000000 -0.030273437500000000000000000000\n",
       " -0.037109375000000000000000000000 -0.047851562500000000000000000000 -0.047851562500000000000000000000\n",
       "\n",
       "(1 ,62,.,.) = \n",
       " 0.049804687500000000000000000000 0.006835937500000000000000000000 0.039062500000000000000000000000\n",
       " -0.073242187500000000000000000000 -0.093750000000000000000000000000 -0.040039062500000000000000000000\n",
       " -0.027343750000000000000000000000 -0.113281250000000000000000000000 0.027343750000000000000000000000\n",
       "\n",
       "(1 ,63,.,.) = \n",
       " 0.069335937500000000000000000000 -0.021484375000000000000000000000 0.016601562500000000000000000000\n",
       " -0.035156250000000000000000000000 -0.118164062500000000000000000000 -0.048828125000000000000000000000\n",
       " 0.064453125000000000000000000000 -0.026367187500000000000000000000 -0.009765625000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " 0.393554687500000000000000000000 -0.285156250000000000000000000000 -0.214843750000000000000000000000\n",
       " -0.092773437500000000000000000000 0.273437500000000000000000000000 0.163085937500000000000000000000\n",
       " 0.347656250000000000000000000000 -0.038085937500000000000000000000 -0.068359375000000000000000000000\n",
       "\n",
       "(2 ,1 ,.,.) = \n",
       " -0.027343750000000000000000000000 0.003906250000000000000000000000 -0.523437500000000000000000000000\n",
       " -0.187500000000000000000000000000 -0.007812500000000000000000000000 -0.071289062500000000000000000000\n",
       " -0.238281250000000000000000000000 -0.067382812500000000000000000000 0.127929687500000000000000000000\n",
       "\n",
       "(2 ,2 ,.,.) = \n",
       " 0.031250000000000000000000000000 -0.078125000000000000000000000000 -0.101562500000000000000000000000\n",
       " -0.011718750000000000000000000000 -0.045898437500000000000000000000 0.064453125000000000000000000000\n",
       " -0.025390625000000000000000000000 0.068359375000000000000000000000 0.076171875000000000000000000000\n",
       "   ...\n",
       "\n",
       "(2 ,61,.,.) = \n",
       " 0.046875000000000000000000000000 0.008789062500000000000000000000 -0.043945312500000000000000000000\n",
       " -0.026367187500000000000000000000 -0.015625000000000000000000000000 0.116210937500000000000000000000\n",
       " 0.055664062500000000000000000000 -0.040039062500000000000000000000 0.053710937500000000000000000000\n",
       "\n",
       "(2 ,62,.,.) = \n",
       " 0.121093750000000000000000000000 0.004882812500000000000000000000 -0.028320312500000000000000000000\n",
       " -0.022460937500000000000000000000 0.074218750000000000000000000000 -0.006835937500000000000000000000\n",
       " 0.015625000000000000000000000000 0.012695312500000000000000000000 -0.029296875000000000000000000000\n",
       "\n",
       "(2 ,63,.,.) = \n",
       " 0.060546875000000000000000000000 0.016601562500000000000000000000 0.000976562500000000000000000000\n",
       " -0.153320312500000000000000000000 -0.046875000000000000000000000000 0.054687500000000000000000000000\n",
       " -0.154296875000000000000000000000 0.076171875000000000000000000000 0.003906250000000000000000000000\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(29,0 ,.,.) = \n",
       " -0.057617187500000000000000000000 -0.036132812500000000000000000000 -0.007812500000000000000000000000\n",
       " -0.043945312500000000000000000000 -0.033203125000000000000000000000 -0.044921875000000000000000000000\n",
       " 0.051757812500000000000000000000 -0.099609375000000000000000000000 -0.052734375000000000000000000000\n",
       "\n",
       "(29,1 ,.,.) = \n",
       " 0.055664062500000000000000000000 -0.021484375000000000000000000000 0.042968750000000000000000000000\n",
       " 0.037109375000000000000000000000 -0.025390625000000000000000000000 0.000000000000000000000000000000\n",
       " 0.006835937500000000000000000000 -0.046875000000000000000000000000 -0.084960937500000000000000000000\n",
       "\n",
       "(29,2 ,.,.) = \n",
       " -0.078125000000000000000000000000 -0.064453125000000000000000000000 -0.059570312500000000000000000000\n",
       " 0.054687500000000000000000000000 0.020507812500000000000000000000 0.000000000000000000000000000000\n",
       " -0.040039062500000000000000000000 -0.097656250000000000000000000000 -0.113281250000000000000000000000\n",
       "   ...\n",
       "\n",
       "(29,61,.,.) = \n",
       " 0.049804687500000000000000000000 -0.032226562500000000000000000000 -0.072265625000000000000000000000\n",
       " -0.089843750000000000000000000000 0.037109375000000000000000000000 -0.054687500000000000000000000000\n",
       " -0.115234375000000000000000000000 0.061523437500000000000000000000 0.062500000000000000000000000000\n",
       "\n",
       "(29,62,.,.) = \n",
       " 0.039062500000000000000000000000 0.005859375000000000000000000000 -0.065429687500000000000000000000\n",
       " -0.002929687500000000000000000000 0.104492187500000000000000000000 0.026367187500000000000000000000\n",
       " 0.148437500000000000000000000000 -0.057617187500000000000000000000 -0.026367187500000000000000000000\n",
       "\n",
       "(29,63,.,.) = \n",
       " -0.046875000000000000000000000000 0.008789062500000000000000000000 -0.090820312500000000000000000000\n",
       " 0.009765625000000000000000000000 -0.038085937500000000000000000000 -0.151367187500000000000000000000\n",
       " 0.101562500000000000000000000000 0.035156250000000000000000000000 -0.037109375000000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(30,0 ,.,.) = \n",
       " 0.052734375000000000000000000000 -0.096679687500000000000000000000 -0.033203125000000000000000000000\n",
       " 0.126953125000000000000000000000 -0.084960937500000000000000000000 0.003906250000000000000000000000\n",
       " 0.035156250000000000000000000000 0.003906250000000000000000000000 0.095703125000000000000000000000\n",
       "\n",
       "(30,1 ,.,.) = \n",
       " 0.032226562500000000000000000000 0.163085937500000000000000000000 0.026367187500000000000000000000\n",
       " -0.038085937500000000000000000000 0.072265625000000000000000000000 0.049804687500000000000000000000\n",
       " 0.071289062500000000000000000000 -0.069335937500000000000000000000 -0.022460937500000000000000000000\n",
       "\n",
       "(30,2 ,.,.) = \n",
       " 0.010742187500000000000000000000 -0.019531250000000000000000000000 0.022460937500000000000000000000\n",
       " -0.059570312500000000000000000000 -0.007812500000000000000000000000 -0.022460937500000000000000000000\n",
       " -0.077148437500000000000000000000 0.050781250000000000000000000000 -0.038085937500000000000000000000\n",
       "   ...\n",
       "\n",
       "(30,61,.,.) = \n",
       " 0.035156250000000000000000000000 0.032226562500000000000000000000 0.007812500000000000000000000000\n",
       " 0.041992187500000000000000000000 0.015625000000000000000000000000 -0.083007812500000000000000000000\n",
       " -0.000976562500000000000000000000 0.013671875000000000000000000000 0.002929687500000000000000000000\n",
       "\n",
       "(30,62,.,.) = \n",
       " 0.055664062500000000000000000000 -0.004882812500000000000000000000 -0.029296875000000000000000000000\n",
       " -0.099609375000000000000000000000 0.045898437500000000000000000000 -0.018554687500000000000000000000\n",
       " 0.055664062500000000000000000000 -0.013671875000000000000000000000 0.011718750000000000000000000000\n",
       "\n",
       "(30,63,.,.) = \n",
       " -0.067382812500000000000000000000 0.041992187500000000000000000000 -0.057617187500000000000000000000\n",
       " -0.013671875000000000000000000000 -0.008789062500000000000000000000 0.018554687500000000000000000000\n",
       " 0.048828125000000000000000000000 -0.012695312500000000000000000000 -0.069335937500000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(31,0 ,.,.) = \n",
       " 0.016601562500000000000000000000 -0.129882812500000000000000000000 -0.088867187500000000000000000000\n",
       " -0.091796875000000000000000000000 -0.159179687500000000000000000000 0.197265625000000000000000000000\n",
       " 0.020507812500000000000000000000 0.087890625000000000000000000000 -0.091796875000000000000000000000\n",
       "\n",
       "(31,1 ,.,.) = \n",
       " 0.075195312500000000000000000000 0.183593750000000000000000000000 0.157226562500000000000000000000\n",
       " -0.018554687500000000000000000000 -0.015625000000000000000000000000 -0.130859375000000000000000000000\n",
       " -0.017578125000000000000000000000 0.000976562500000000000000000000 -0.020507812500000000000000000000\n",
       "\n",
       "(31,2 ,.,.) = \n",
       " -0.009765625000000000000000000000 0.019531250000000000000000000000 0.064453125000000000000000000000\n",
       " -0.015625000000000000000000000000 0.037109375000000000000000000000 0.025390625000000000000000000000\n",
       " -0.011718750000000000000000000000 0.046875000000000000000000000000 0.039062500000000000000000000000\n",
       "   ...\n",
       "\n",
       "(31,61,.,.) = \n",
       " -0.018554687500000000000000000000 -0.093750000000000000000000000000 0.006835937500000000000000000000\n",
       " 0.000000000000000000000000000000 -0.074218750000000000000000000000 -0.086914062500000000000000000000\n",
       " -0.025390625000000000000000000000 -0.033203125000000000000000000000 0.020507812500000000000000000000\n",
       "\n",
       "(31,62,.,.) = \n",
       " 0.083984375000000000000000000000 -0.040039062500000000000000000000 0.009765625000000000000000000000\n",
       " 0.017578125000000000000000000000 0.107421875000000000000000000000 0.032226562500000000000000000000\n",
       " 0.090820312500000000000000000000 0.041015625000000000000000000000 -0.105468750000000000000000000000\n",
       "\n",
       "(31,63,.,.) = \n",
       " 0.085937500000000000000000000000 0.006835937500000000000000000000 0.140625000000000000000000000000\n",
       " 0.017578125000000000000000000000 0.014648437500000000000000000000 0.100585937500000000000000000000\n",
       " 0.076171875000000000000000000000 0.014648437500000000000000000000 -0.005859375000000000000000000000\n",
       "[torch.cuda.FloatTensor of size 32x64x3x3 (GPU 0)]\n",
       "), ('conv3.bias', \n",
       "1.00000e-02 *\n",
       " -0.955200195312500000000000000000\n",
       " -2.526855468750000000000000000000\n",
       " 0.668334960937500000000000000000\n",
       " -2.005004882812500000000000000000\n",
       " 3.741455078125000000000000000000\n",
       " 1.446533203125000000000000000000\n",
       " 1.385498046875000000000000000000\n",
       " 1.620483398437500000000000000000\n",
       " 4.177856445312500000000000000000\n",
       " -0.769042968750000000000000000000\n",
       " -0.677490234375000000000000000000\n",
       " 0.051879882812500000000000000000\n",
       " -3.262329101562500000000000000000\n",
       " -0.213623046875000000000000000000\n",
       " -1.733398437500000000000000000000\n",
       " -2.859497070312500000000000000000\n",
       " -0.247192382812500000000000000000\n",
       " 4.055786132812500000000000000000\n",
       " 0.781250000000000000000000000000\n",
       " 1.284790039062500000000000000000\n",
       " 0.018310546875000000000000000000\n",
       " 2.569580078125000000000000000000\n",
       " -4.019165039062500000000000000000\n",
       " -0.955200195312500000000000000000\n",
       " 1.708984375000000000000000000000\n",
       " -0.344848632812500000000000000000\n",
       " 1.901245117187500000000000000000\n",
       " 3.890991210937500000000000000000\n",
       " 4.132080078125000000000000000000\n",
       " 3.109741210937500000000000000000\n",
       " 0.482177734375000000000000000000\n",
       " 0.433349609375000000000000000000\n",
       "[torch.cuda.FloatTensor of size 32 (GPU 0)]\n",
       "), ('conv4.weight', \n",
       "(0 ,0 ,.,.) = \n",
       " 0.032226562500000000000000000000 -0.148681640625000000000000000000 0.059082031250000000000000000000\n",
       " -0.046630859375000000000000000000 -0.012451171875000000000000000000 0.042724609375000000000000000000\n",
       " 0.019531250000000000000000000000 -0.003173828125000000000000000000 -0.015625000000000000000000000000\n",
       "\n",
       "(0 ,1 ,.,.) = \n",
       " -0.149902343750000000000000000000 -0.010009765625000000000000000000 0.030029296875000000000000000000\n",
       " 0.014160156250000000000000000000 -0.008544921875000000000000000000 0.017333984375000000000000000000\n",
       " 0.004394531250000000000000000000 -0.005126953125000000000000000000 0.104980468750000000000000000000\n",
       "\n",
       "(0 ,2 ,.,.) = \n",
       " -0.042480468750000000000000000000 0.011474609375000000000000000000 -0.005371093750000000000000000000\n",
       " 0.256347656250000000000000000000 -0.048583984375000000000000000000 0.022705078125000000000000000000\n",
       " 0.117431640625000000000000000000 0.045654296875000000000000000000 -0.020996093750000000000000000000\n",
       "   ...\n",
       "\n",
       "(0 ,29,.,.) = \n",
       " 0.072753906250000000000000000000 -0.036865234375000000000000000000 0.054199218750000000000000000000\n",
       " 0.136230468750000000000000000000 -0.079589843750000000000000000000 0.012939453125000000000000000000\n",
       " -0.021728515625000000000000000000 0.060302734375000000000000000000 -0.082763671875000000000000000000\n",
       "\n",
       "(0 ,30,.,.) = \n",
       " -0.006591796875000000000000000000 -0.004882812500000000000000000000 -0.047363281250000000000000000000\n",
       " 0.049804687500000000000000000000 0.023681640625000000000000000000 0.026123046875000000000000000000\n",
       " -0.014404296875000000000000000000 0.028564453125000000000000000000 0.023681640625000000000000000000\n",
       "\n",
       "(0 ,31,.,.) = \n",
       " 0.131835937500000000000000000000 -0.111328125000000000000000000000 0.008789062500000000000000000000\n",
       " 0.110595703125000000000000000000 0.017822265625000000000000000000 -0.071289062500000000000000000000\n",
       " -0.063964843750000000000000000000 -0.005615234375000000000000000000 0.010498046875000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -0.054443359375000000000000000000 0.152832031250000000000000000000 -0.028808593750000000000000000000\n",
       " 0.010253906250000000000000000000 -0.004394531250000000000000000000 0.006591796875000000000000000000\n",
       " -0.003173828125000000000000000000 0.031494140625000000000000000000 -0.019287109375000000000000000000\n",
       "\n",
       "(1 ,1 ,.,.) = \n",
       " 0.059814453125000000000000000000 0.002441406250000000000000000000 -0.010742187500000000000000000000\n",
       " 0.080810546875000000000000000000 0.156982421875000000000000000000 -0.077392578125000000000000000000\n",
       " -0.014404296875000000000000000000 -0.054931640625000000000000000000 -0.075195312500000000000000000000\n",
       "\n",
       "(1 ,2 ,.,.) = \n",
       " -0.038085937500000000000000000000 -0.011718750000000000000000000000 -0.001464843750000000000000000000\n",
       " 0.131591796875000000000000000000 0.126220703125000000000000000000 -0.025878906250000000000000000000\n",
       " 0.050537109375000000000000000000 0.103759765625000000000000000000 0.013916015625000000000000000000\n",
       "   ...\n",
       "\n",
       "(1 ,29,.,.) = \n",
       " -0.089599609375000000000000000000 0.011718750000000000000000000000 0.078613281250000000000000000000\n",
       " 0.053222656250000000000000000000 0.037841796875000000000000000000 -0.051269531250000000000000000000\n",
       " 0.011718750000000000000000000000 -0.072021484375000000000000000000 0.093750000000000000000000000000\n",
       "\n",
       "(1 ,30,.,.) = \n",
       " 0.022705078125000000000000000000 0.078369140625000000000000000000 -0.001464843750000000000000000000\n",
       " -0.043212890625000000000000000000 0.032226562500000000000000000000 -0.131347656250000000000000000000\n",
       " -0.031250000000000000000000000000 -0.012939453125000000000000000000 -0.008056640625000000000000000000\n",
       "\n",
       "(1 ,31,.,.) = \n",
       " 0.094970703125000000000000000000 -0.137451171875000000000000000000 -0.059082031250000000000000000000\n",
       " 0.104248046875000000000000000000 0.004394531250000000000000000000 -0.023193359375000000000000000000\n",
       " -0.060546875000000000000000000000 0.039062500000000000000000000000 -0.005371093750000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       " 0.020996093750000000000000000000 -0.083740234375000000000000000000 0.022460937500000000000000000000\n",
       " -0.014648437500000000000000000000 -0.064941406250000000000000000000 0.038818359375000000000000000000\n",
       " -0.014892578125000000000000000000 -0.010498046875000000000000000000 0.017822265625000000000000000000\n",
       "\n",
       "(2 ,1 ,.,.) = \n",
       " -0.073242187500000000000000000000 0.021972656250000000000000000000 0.015136718750000000000000000000\n",
       " -0.050781250000000000000000000000 0.032470703125000000000000000000 -0.057861328125000000000000000000\n",
       " 0.013916015625000000000000000000 -0.032958984375000000000000000000 -0.001464843750000000000000000000\n",
       "\n",
       "(2 ,2 ,.,.) = \n",
       " 0.031982421875000000000000000000 0.020263671875000000000000000000 -0.012695312500000000000000000000\n",
       " -0.051269531250000000000000000000 -0.028564453125000000000000000000 0.005371093750000000000000000000\n",
       " -0.181396484375000000000000000000 -0.082519531250000000000000000000 0.004882812500000000000000000000\n",
       "   ...\n",
       "\n",
       "(2 ,29,.,.) = \n",
       " 0.002685546875000000000000000000 0.038085937500000000000000000000 0.173583984375000000000000000000\n",
       " -0.026611328125000000000000000000 0.048583984375000000000000000000 -0.000732421875000000000000000000\n",
       " -0.098388671875000000000000000000 -0.068115234375000000000000000000 -0.072509765625000000000000000000\n",
       "\n",
       "(2 ,30,.,.) = \n",
       " 0.035400390625000000000000000000 0.037109375000000000000000000000 -0.040527343750000000000000000000\n",
       " 0.070068359375000000000000000000 -0.026123046875000000000000000000 0.014160156250000000000000000000\n",
       " 0.086914062500000000000000000000 -0.010253906250000000000000000000 -0.006103515625000000000000000000\n",
       "\n",
       "(2 ,31,.,.) = \n",
       " 0.014160156250000000000000000000 -0.093994140625000000000000000000 0.013916015625000000000000000000\n",
       " 0.021484375000000000000000000000 -0.008056640625000000000000000000 -0.007568359375000000000000000000\n",
       " 0.019531250000000000000000000000 0.065185546875000000000000000000 -0.038330078125000000000000000000\n",
       "     ⋮ \n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       " -0.057861328125000000000000000000 0.031982421875000000000000000000 0.048095703125000000000000000000\n",
       " -0.012695312500000000000000000000 0.148437500000000000000000000000 -0.079101562500000000000000000000\n",
       " -0.001464843750000000000000000000 -0.009277343750000000000000000000 0.009765625000000000000000000000\n",
       "\n",
       "(3 ,1 ,.,.) = \n",
       " 0.014160156250000000000000000000 -0.123046875000000000000000000000 0.006591796875000000000000000000\n",
       " -0.086914062500000000000000000000 0.047607421875000000000000000000 0.028320312500000000000000000000\n",
       " 0.038574218750000000000000000000 -0.010986328125000000000000000000 -0.044921875000000000000000000000\n",
       "\n",
       "(3 ,2 ,.,.) = \n",
       " 0.026611328125000000000000000000 0.028808593750000000000000000000 0.008056640625000000000000000000\n",
       " -0.090332031250000000000000000000 -0.013916015625000000000000000000 -0.008300781250000000000000000000\n",
       " -0.142333984375000000000000000000 -0.130615234375000000000000000000 0.009033203125000000000000000000\n",
       "   ...\n",
       "\n",
       "(3 ,29,.,.) = \n",
       " 0.084472656250000000000000000000 -0.076416015625000000000000000000 -0.038085937500000000000000000000\n",
       " 0.040527343750000000000000000000 -0.101806640625000000000000000000 -0.068359375000000000000000000000\n",
       " -0.026367187500000000000000000000 0.028808593750000000000000000000 0.045654296875000000000000000000\n",
       "\n",
       "(3 ,30,.,.) = \n",
       " 0.043212890625000000000000000000 0.034423828125000000000000000000 0.037109375000000000000000000000\n",
       " 0.023437500000000000000000000000 0.065673828125000000000000000000 0.034912109375000000000000000000\n",
       " -0.052001953125000000000000000000 0.002441406250000000000000000000 -0.038330078125000000000000000000\n",
       "\n",
       "(3 ,31,.,.) = \n",
       " 0.019775390625000000000000000000 -0.102294921875000000000000000000 -0.008544921875000000000000000000\n",
       " 0.116210937500000000000000000000 0.002197265625000000000000000000 0.040283203125000000000000000000\n",
       " -0.041259765625000000000000000000 -0.020507812500000000000000000000 -0.003417968750000000000000000000\n",
       "[torch.cuda.FloatTensor of size 4x32x3x3 (GPU 0)]\n",
       "), ('conv4.bias', \n",
       "1.00000e-02 *\n",
       " 4.672241210937500000000000000000\n",
       " 0.524902343750000000000000000000\n",
       " -0.473022460937500000000000000000\n",
       " 2.603149414062500000000000000000\n",
       "[torch.cuda.FloatTensor of size 4 (GPU 0)]\n",
       ")])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits=12\n",
    "torch.set_printoptions(precision=30)\n",
    "state_dict_quant.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.measure as na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
