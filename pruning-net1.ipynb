{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse,random\n",
    "from math import log10\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data import get_training_set, get_test_set\n",
    "from torch.nn.modules.module import _addindent\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1을 사용할시에\n",
    "from net.model import Net\n",
    "# model 2을 사용할시에\n",
    "#from net.model_dw import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda import\n",
    "cuda = True\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "torch.manual_seed(random.randint(1,1000))\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset import\n",
    "train_set = get_training_set(2,\"BSDS300\")\n",
    "test_set = get_test_set(2,\"BSDS300\")\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=6, batch_size=16, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=6, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_factor=2\n",
    "train=Net(upscale_factor)\n",
    "weight_name='weight1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weigh\n",
    "model=torch.load(weight_name)\n",
    "keys=model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "___\n",
    "\n",
    "```\n",
    "self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "self.conv2=nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "self.conv3=nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "__upscale_factor는 2 이다__\n",
    "\n",
    "<br><br>\n",
    "####  weight1 초기 PSNR\n",
    "\n",
    "```\n",
    "===> Avg. PSNR: 27.7404 dB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning method\n",
    "___\n",
    "\n",
    "1. Pruning을 할 수 있는 spot을 선택 \n",
    "1. 1개를 선택하여 prunging 한 후에 Net의 아키텍쳐를 바꾼다.\n",
    "1. L1 norm 을 기준으로 pruning 한다.\n",
    "1. PSNR 값을 구한다.\n",
    "1. retraining을 진행.\n",
    "1. 반복(일정 PSNR 이하 로 내려가기전까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def modify(net,alpha=64,beta=64,gamma=32):\n",
    "    \"\"\"\n",
    "    네트워크와 하이퍼 파라미터를 입력받아\n",
    "    네트워크를 하이퍼 파라미터에 맞게 변형한다.\n",
    "    \"\"\"\n",
    "    net.conv1 = nn.Conv2d(1, alpha, (5, 5), (1, 1), (2, 2))\n",
    "    net.conv2=nn.Conv2d(alpha, beta, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv3=nn.Conv2d(beta, gamma, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv4 = nn.Conv2d(gamma, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "    \n",
    "def PSNR(net):\n",
    "    '''\n",
    "    네트워크 를 받아서 psnr 값을 구하여 반환한다.\n",
    "    테스트 배치 만큼 수행 평균\n",
    "    '''\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target=target.cuda()\n",
    "        prediction = net(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "    return avg_psnr/len(testing_data_loader)\n",
    "\n",
    "def _train(net,epoch=50):\n",
    "    '''\n",
    "    네트워크와 에폭,학습률을 입력 받아 그에 맞게 학습시킨다.\n",
    "    '''\n",
    "    #net=nn.DataParallel(net) 이렇게 하는게 더 느리다 % time으로 확인\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(input), target)\n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n",
    "    if epoch%10 is 0:\n",
    "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "\n",
    "def rank(_list):\n",
    "    '''\n",
    "    _list를 입력받아 계산한뒤 pruning 할 (conv,weight)의 위치를 tuple로 반환한다.\n",
    "    pruning 할 layer를 고른다.\n",
    "    기준은 L2와 PSNR 을 기준으로 rank를 만든 뒤 합하여 결정한다.\n",
    "    '''\n",
    "    df=DataFrame(_list,columns=['conv','weight','psnr','L2'])\n",
    "    df['rank']=df['psnr'].rank( ascending=False,method='max')+df['L2'].rank(method='max')\n",
    "    for idx,i in enumerate(df[\"L2\"]):\n",
    "        if i == min(df[\"L2\"]):\n",
    "            print(df['conv'][idx],\"th conv's \",df['weight'][idx],\"'s layer will pruning\")\n",
    "            return(df['conv'][idx],df['weight'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pruning(_model,_weight_soruce,retrain=True,epoch=200):\n",
    "    _weight=deepcopy(_weight_soruce)\n",
    "    print(\"===> Starting Calculate Pruning\")\n",
    "    keys_list=list(_weight.keys())\n",
    "    temp=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        temp.append(len(_weight[keys_list[i]]))\n",
    "    alpha,beta,gamma=temp\n",
    "    print(alpha,beta,gamma)\n",
    "    psnr_list=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        if i is 0:\n",
    "            alpha-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        elif i is 2:\n",
    "            alpha+=1\n",
    "            beta-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        elif i is 4:\n",
    "            beta+=1\n",
    "            gamma-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        for j in range(len(_weight[keys_list[i]])):\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "            weight_matrix=_weight[keys_list[i]]\n",
    "            bias_matrix=_weight[keys_list[i+1]]\n",
    "            temp_weight=0\n",
    "            if j is 0:\n",
    "                temp_weight=weight_matrix[0].abs().sum()\n",
    "                _weight[keys_list[i]]=weight_matrix[1:len(_weight[keys_list[i]])]\n",
    "                _weight[keys_list[i+1]]=bias_matrix[1:len(_weight[keys_list[i]])+1]        \n",
    "            elif j is len(_weight[keys_list[i]])-1:\n",
    "                temp_weight=weight_matrix[len(_weight[keys_list[i]])-1].abs().sum()\n",
    "                _weight[keys_list[i]]=weight_matrix[0:len(_weight[keys_list[i]])-1]                    \n",
    "                _weight[keys_list[i+1]]=bias_matrix[0:len(_weight[keys_list[i]])]\n",
    "            else:\n",
    "                temp_weight=weight_matrix[j].abs().sum()\n",
    "                _weight[keys_list[i]]=torch.cat((weight_matrix[0:j],weight_matrix[j+1:len(_weight[keys_list[i]])]))\n",
    "                _weight[keys_list[i+1]]=torch.cat((bias_matrix[0:j],bias_matrix[j+1:len(_weight[keys_list[i]])+1]))\n",
    "            if i is 0:\n",
    "                _weight[keys_list[i+2]].resize_(alpha,beta,3,3)\n",
    "                _weight[keys_list[i+3]].resize_(beta)\n",
    "            elif i is 2:\n",
    "                _weight[keys_list[i+1]].resize_(beta)\n",
    "                _weight[keys_list[i+3]].resize_(gamma)\n",
    "                _weight[keys_list[i+2]].resize_(beta,gamma,3,3)\n",
    "                _weight[keys_list[i]].resize_(alpha,beta,3,3)\n",
    "            elif i is 4:\n",
    "                _weight[keys_list[i]].resize_(beta,gamma,3,3)\n",
    "                _weight[keys_list[i-2]].resize_(alpha,beta,3,3)\n",
    "                _weight[keys_list[i-1]].resize_(beta)\n",
    "                _weight[keys_list[i+1]].resize_(gamma)\n",
    "                _weight[keys_list[i+2]].resize_(gamma,upscale_factor ** 2,3,3)\n",
    "                _weight[keys_list[i+3]].resize_(upscale_factor ** 2)\n",
    "            _model.load_state_dict(_weight)\n",
    "            _model=_model.cuda()\n",
    "            if retrain is True:\n",
    "                for k in range(0,epoch):\n",
    "                    _train(_model,k)\n",
    "            prnr=PSNR(_model)\n",
    "            print('conv:',i,' num:',j,' psnr:',prnr,' size:',temp_weight)\n",
    "            psnr_list.append(tuple([i,j,prnr,temp_weight]))\n",
    "    return psnr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pruning(_model,_weight,index,epoch=50):\n",
    "    \"\"\"\n",
    "    _model: 모델을 받는다.\n",
    "    _weight:weight값을 받는다.\n",
    "    index: pruning을 시행할 convolution 의 index 값을 받는다.\n",
    "    epoch: pruning후 retrain 할 횟수\n",
    "    \"\"\"\n",
    "    keys_list=list(_weight.keys())\n",
    "    temp=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        temp.append(len(_weight[keys_list[i]]))\n",
    "    alpha,beta,gamma=temp\n",
    "    i=0\n",
    "    j=index[1]\n",
    "    if index[0] is 1:\n",
    "        i=0\n",
    "        alpha-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    elif index[0] is 2:\n",
    "        i=2\n",
    "        beta-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    elif index[0] is 3:\n",
    "        i=4\n",
    "        gamma-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    if j>len(_weight[keys_list[i]]):\n",
    "        print(\"illegal pruning\")\n",
    "        return\n",
    "    weight_matrix=_weight[keys_list[i]]\n",
    "    bias_matrix=_weight[keys_list[i+1]]\n",
    "    if index[1] is 0:\n",
    "        _weight[keys_list[i]]=weight_matrix[1:len(_weight[keys_list[i]])]\n",
    "        _weight[keys_list[i+1]]=bias_matrix[1:len(_weight[keys_list[i]])+1]\n",
    "    elif j is len(model[keys_list[i]])-1:\n",
    "        _weight[keys_list[i]]=weight_matrix[0:len(_weight[keys_list[i]])-1]\n",
    "        _weight[keys_list[i+1]]=bias_matrix[0:len(_weight[keys_list[i]])]\n",
    "    else:\n",
    "        _weight[keys_list[i]]=torch.cat((weight_matrix[0:j],weight_matrix[j+1:len(_weight[keys_list[i]])]))\n",
    "        _weight[keys_list[i+1]]=torch.cat((bias_matrix[0:j],bias_matrix[j+1:len(_weight[keys_list[i]])+1]))\n",
    "    if i is 0:\n",
    "        _weight[keys_list[i+2]].resize_(alpha,beta,3,3)\n",
    "        _weight[keys_list[i+3]].resize_(beta)\n",
    "    elif i is 2:\n",
    "        _weight[keys_list[i+1]].resize_(beta)\n",
    "        _weight[keys_list[i+3]].resize_(gamma)\n",
    "        _weight[keys_list[i+2]].resize_(beta,gamma,3,3)\n",
    "        _weight[keys_list[i]].resize_(alpha,beta,3,3)\n",
    "    elif i is 4:\n",
    "        _weight[keys_list[i]].resize_(beta,gamma,3,3)\n",
    "        _weight[keys_list[i-2]].resize_(alpha,beta,3,3)\n",
    "        _weight[keys_list[i-1]].resize_(beta)\n",
    "        _weight[keys_list[i+1]].resize_(gamma)\n",
    "        _weight[keys_list[i+2]].resize_(gamma,upscale_factor ** 2,3,3)\n",
    "        _weight[keys_list[i+3]].resize_(upscale_factor ** 2)\n",
    "    _model=_model.cuda()\n",
    "    for k in range(0,epoch):\n",
    "        _train(_model,k)\n",
    "    prnr=PSNR(_model)\n",
    "    print('conv:',index[0],' num:',j,'is pruning psnr:',prnr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Starting Calculate Pruning\n",
      "64 64 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py:514: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 0 Complete: Avg. Loss: 0.2204\n",
      "conv: 0  num: 0  psnr: 22.57898349758568  size: 2.926562786102295\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2178\n",
      "conv: 0  num: 1  psnr: 22.23948825974483  size: 3.5600385665893555\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2154\n",
      "conv: 0  num: 2  psnr: 22.01875357781445  size: 2.7003331184387207\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1708\n",
      "conv: 0  num: 3  psnr: 22.75825348331718  size: 3.595670461654663\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1823\n",
      "conv: 0  num: 4  psnr: 22.052491650819057  size: 3.4622962474823\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1912\n",
      "conv: 0  num: 5  psnr: 22.100526723724716  size: 3.3184256553649902\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1880\n",
      "conv: 0  num: 6  psnr: 20.91629834052434  size: 4.114063739776611\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1853\n",
      "conv: 0  num: 7  psnr: 18.3122495134088  size: 3.536667823791504\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1739\n",
      "conv: 0  num: 8  psnr: 22.84121436006975  size: 3.7133820056915283\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1844\n",
      "conv: 0  num: 9  psnr: 23.870267729177602  size: 3.8943541049957275\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1757\n",
      "conv: 0  num: 10  psnr: 20.871937982829674  size: 3.2882728576660156\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1889\n",
      "conv: 0  num: 11  psnr: 22.45252688735279  size: 3.313321113586426\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2230\n",
      "conv: 0  num: 12  psnr: 22.891668162229188  size: 3.788851499557495\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2626\n",
      "conv: 0  num: 13  psnr: 17.914485769652977  size: 3.192880392074585\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2251\n",
      "conv: 0  num: 14  psnr: 20.13170630446865  size: 3.399325370788574\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2347\n",
      "conv: 0  num: 15  psnr: 21.305874548883807  size: 2.5385217666625977\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2533\n",
      "conv: 0  num: 16  psnr: 21.408923542862986  size: 3.666475534439087\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2320\n",
      "conv: 0  num: 17  psnr: 19.40425887669408  size: 3.028347969055176\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2289\n",
      "conv: 0  num: 18  psnr: 21.60913837501909  size: 3.0369980335235596\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2115\n",
      "conv: 0  num: 19  psnr: 22.035127278248563  size: 3.623494863510132\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2240\n",
      "conv: 0  num: 20  psnr: 22.48120767813484  size: 4.507632732391357\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2259\n",
      "conv: 0  num: 21  psnr: 20.721403832392312  size: 4.4181718826293945\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2294\n",
      "conv: 0  num: 22  psnr: 19.13912782024969  size: 3.20487642288208\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2402\n",
      "conv: 0  num: 23  psnr: 19.987675656210737  size: 3.7541511058807373\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1915\n",
      "conv: 0  num: 24  psnr: 19.133416037585704  size: 3.6289429664611816\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1996\n",
      "conv: 0  num: 25  psnr: 22.47536995152421  size: 3.1502187252044678\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1708\n",
      "conv: 0  num: 26  psnr: 23.09989225572524  size: 4.05465841293335\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1717\n",
      "conv: 0  num: 27  psnr: 21.83780248338984  size: 3.0270135402679443\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1767\n",
      "conv: 0  num: 28  psnr: 16.797135876974295  size: 3.27731990814209\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2117\n",
      "conv: 0  num: 29  psnr: 22.028337968355647  size: 3.9907984733581543\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1937\n",
      "conv: 0  num: 30  psnr: 19.901897606219613  size: 4.119686126708984\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2015\n",
      "conv: 0  num: 31  psnr: 21.569666591219693  size: 3.4438977241516113\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2069\n",
      "conv: 0  num: 32  psnr: 22.005398594076617  size: 3.987121343612671\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2120\n",
      "conv: 0  num: 33  psnr: 18.069393033702976  size: 4.550487518310547\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2090\n",
      "conv: 0  num: 34  psnr: 22.370753434835848  size: 3.6898210048675537\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2402\n",
      "conv: 0  num: 35  psnr: 22.695441666492897  size: 3.15950345993042\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2264\n",
      "conv: 0  num: 36  psnr: 21.566438396634126  size: 3.5656967163085938\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2226\n",
      "conv: 0  num: 37  psnr: 21.975220246358806  size: 3.4216361045837402\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2430\n",
      "conv: 0  num: 38  psnr: 22.092219237281746  size: 2.4204752445220947\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2662\n",
      "conv: 0  num: 39  psnr: 22.113070460990215  size: 7.463708400726318\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2326\n",
      "conv: 0  num: 40  psnr: 18.947554895553534  size: 3.291673183441162\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2561\n",
      "conv: 0  num: 41  psnr: 20.218248311882885  size: 3.303051710128784\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2323\n",
      "conv: 0  num: 42  psnr: 19.556843396078914  size: 2.8272957801818848\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2158\n",
      "conv: 0  num: 43  psnr: 21.694799917022372  size: 2.9348325729370117\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2216\n",
      "conv: 0  num: 44  psnr: 17.454372609342496  size: 3.683912992477417\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2090\n",
      "conv: 0  num: 45  psnr: 21.125362299035597  size: 2.943221092224121\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2175\n",
      "conv: 0  num: 46  psnr: 21.148312456601627  size: 3.127673387527466\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2174\n",
      "conv: 0  num: 47  psnr: 21.666035269935232  size: 3.9300012588500977\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1947\n",
      "conv: 0  num: 48  psnr: 21.510604748275135  size: 4.009859085083008\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1770\n",
      "conv: 0  num: 49  psnr: 17.706650556980268  size: 3.2004384994506836\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1359\n",
      "conv: 0  num: 50  psnr: 21.52384221222253  size: 3.247309446334839\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1298\n",
      "conv: 0  num: 51  psnr: 21.10504568370763  size: 3.6704821586608887\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1242\n",
      "conv: 0  num: 52  psnr: 21.167925442377253  size: 3.3864877223968506\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1385\n",
      "conv: 0  num: 53  psnr: 22.03302329126782  size: 2.581829309463501\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1470\n",
      "conv: 0  num: 54  psnr: 20.71641289224487  size: 4.3378520011901855\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1436\n",
      "conv: 0  num: 55  psnr: 21.696750714203507  size: 3.335524797439575\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1237\n",
      "conv: 0  num: 56  psnr: 20.70451640131937  size: 3.4207117557525635\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1148\n",
      "conv: 0  num: 57  psnr: 21.53257836758542  size: 3.569721221923828\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0995\n",
      "conv: 0  num: 58  psnr: 19.842590287085457  size: 3.6195387840270996\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0961\n",
      "conv: 0  num: 59  psnr: 21.61732770972135  size: 2.8329243659973145\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1033\n",
      "conv: 0  num: 60  psnr: 18.591239943191567  size: 3.5531005859375\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0982\n",
      "conv: 0  num: 61  psnr: 21.931012474119985  size: 3.13732647895813\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0829\n",
      "conv: 0  num: 62  psnr: 20.369695303529532  size: 4.168920040130615\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.0995\n",
      "conv: 0  num: 63  psnr: 21.39945812205793  size: 3.7978355884552\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "While copying the parameter named conv2.bias, whose dimensions in the model are torch.Size([63]) and whose dimensions in the checkpoint are torch.Size([65]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m                     \u001b[0mown_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: sizes do not match at /pytorch/torch/lib/THC/generic/THCTensorCopy.c:101",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-127e56699fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpruning\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpruning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlista\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcal_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mindexa\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexa\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-2d3a11ffc271>\u001b[0m in \u001b[0;36mcal_pruning\u001b[0;34m(_model, _weight_soruce, retrain, epoch)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0m_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupscale_factor\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0m_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0m_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretrain\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    517\u001b[0m                                        \u001b[0;34m'whose dimensions in the model are {} and '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                                        \u001b[0;34m'whose dimensions in the checkpoint are {}.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                                        .format(name, own_state[name].size(), param.size()))\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 raise KeyError('unexpected key \"{}\" in state_dict'\n",
      "\u001b[0;31mRuntimeError\u001b[0m: While copying the parameter named conv2.bias, whose dimensions in the model are torch.Size([63]) and whose dimensions in the checkpoint are torch.Size([65])."
     ]
    }
   ],
   "source": [
    "pruning=100\n",
    "for _ in range(1,pruning):\n",
    "    lista=cal_pruning(train,model,epoch=10)\n",
    "    indexa=rank(lista)\n",
    "    _pruning(train,model,indexa,epoch=150)\n",
    "    print(_,\" 번째 pruning 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
