{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse,random\n",
    "from math import log10\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.data import get_training_set, get_test_set\n",
    "from torch.nn.modules.module import _addindent\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1을 사용할시에\n",
    "from net.model import Net\n",
    "# model 2을 사용할시에\n",
    "#from net.model_dw import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda import\n",
    "cuda = True\n",
    "if cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "torch.manual_seed(random.randint(1,1000))\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset import\n",
    "train_set = get_training_set(2,\"BSDS300\")\n",
    "test_set = get_test_set(2,\"BSDS300\")\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=6, batch_size=16, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=6, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscale_factor=2\n",
    "train=Net(upscale_factor)\n",
    "weight_name='weight1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weigh\n",
    "model=torch.load(weight_name)\n",
    "keys=model.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "___\n",
    "\n",
    "```\n",
    "self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "self.conv2=nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "self.conv3=nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "```\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "__upscale_factor는 2 이다__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning method\n",
    "___\n",
    "\n",
    "1. Pruning을 할 수 있는 spot을 선택 \n",
    "1. 1개를 선택하여 prunging 한 후에 Net의 아키텍쳐를 바꾼다.\n",
    "1. L1 norm 을 기준으로 pruning 한다.\n",
    "1. PSNR 값을 구한다.\n",
    "1. retraining을 진행.\n",
    "1. 반복(일정 PSNR 이하 로 내려가기전까지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "def modify(net,alpha=64,beta=64,gamma=32):\n",
    "    \"\"\"\n",
    "    네트워크와 하이퍼 파라미터를 입력받아\n",
    "    네트워크를 하이퍼 파라미터에 맞게 변형한다.\n",
    "    \"\"\"\n",
    "    net.conv1 = nn.Conv2d(1, alpha, (5, 5), (1, 1), (2, 2))\n",
    "    net.conv2=nn.Conv2d(alpha, beta, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv3=nn.Conv2d(beta, gamma, (3, 3), (1, 1), (1, 1))\n",
    "    net.conv4 = nn.Conv2d(gamma, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "    \n",
    "def PSNR(net):\n",
    "    '''\n",
    "    네트워크 를 받아서 psnr 값을 구하여 반환한다.\n",
    "    테스트 배치 만큼 수행 평균\n",
    "    '''\n",
    "    avg_psnr = 0\n",
    "    for batch in testing_data_loader:\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target=target.cuda()\n",
    "        prediction = net(input)\n",
    "        mse = criterion(prediction, target)\n",
    "        psnr = 10 * log10(1 / mse.data[0])\n",
    "        avg_psnr += psnr\n",
    "    return avg_psnr/len(testing_data_loader)\n",
    "\n",
    "def _train(net,epoch=50):\n",
    "    '''\n",
    "    네트워크와 에폭,학습률을 입력 받아 그에 맞게 학습시킨다.\n",
    "    '''\n",
    "    #net=nn.DataParallel(net) 이렇게 하는게 더 느리다 % time으로 확인\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        input, target = Variable(batch[0]), Variable(batch[1])\n",
    "        if cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(net(input), target)\n",
    "        epoch_loss += loss.data[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(training_data_loader), loss.data[0]))\n",
    "    if epoch%10 is 0:\n",
    "        print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
    "\n",
    "def rank(_list):\n",
    "    '''\n",
    "    _list를 입력받아 계산한뒤 pruning 할 (conv,weight)의 위치를 tuple로 반환한다.\n",
    "    pruning 할 layer를 고른다.\n",
    "    기준은 L2와 PSNR 을 기준으로 rank를 만든 뒤 합하여 결정한다.\n",
    "    '''\n",
    "    df=DataFrame(_list,columns=['conv','weight','psnr','L2'])\n",
    "    df['rank']=df['psnr'].rank( ascending=False,method='max')+df['L2'].rank(method='max')\n",
    "    for idx,i in enumerate(df[\"L2\"]):\n",
    "        if i == min(df[\"L2\"]):\n",
    "            print(df['conv'][idx],\"th conv's \",df['weight'][idx],\"'s layer will pruning\")\n",
    "            return(df['conv'][idx],df['weight'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pruning(_model,_weight_soruce,retrain=True,epoch=200):\n",
    "    _weight=deepcopy(_weight_soruce)\n",
    "    print(\"===> Starting Calculate Pruning\")\n",
    "    keys_list=list(_weight.keys())\n",
    "    temp=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        temp.append(len(_weight[keys_list[i]]))\n",
    "    alpha,beta,gamma=temp\n",
    "    print(alpha,beta,gamma)\n",
    "    psnr_list=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        if i is 0:\n",
    "            alpha-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        elif i is 2:\n",
    "            alpha+=1\n",
    "            beta-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        elif i is 4:\n",
    "            beta+=1\n",
    "            gamma-=1\n",
    "            modify(_model,alpha,beta,gamma)\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "        for j in range(len(_weight[keys_list[i]])):\n",
    "            _weight=deepcopy(_weight_soruce)\n",
    "            weight_matrix=_weight[keys_list[i]]\n",
    "            bias_matrix=_weight[keys_list[i+1]]\n",
    "            temp_weight=0\n",
    "            if j is 0:\n",
    "                temp_weight=weight_matrix[0].abs().sum()\n",
    "                _weight[keys_list[i]]=weight_matrix[1:len(_weight[keys_list[i]])]\n",
    "                _weight[keys_list[i+1]]=bias_matrix[1:len(_weight[keys_list[i]])+1]        \n",
    "            elif j is len(_weight[keys_list[i]])-1:\n",
    "                temp_weight=weight_matrix[len(_weight[keys_list[i]])-1].abs().sum()\n",
    "                _weight[keys_list[i]]=weight_matrix[0:len(_weight[keys_list[i]])-1]                    \n",
    "                _weight[keys_list[i+1]]=bias_matrix[0:len(_weight[keys_list[i]])]\n",
    "            else:\n",
    "                temp_weight=weight_matrix[j].abs().sum()\n",
    "                _weight[keys_list[i]]=torch.cat((weight_matrix[0:j],weight_matrix[j+1:len(_weight[keys_list[i]])]))\n",
    "                _weight[keys_list[i+1]]=torch.cat((bias_matrix[0:j],bias_matrix[j+1:len(_weight[keys_list[i]])+1]))\n",
    "            if i is 0:\n",
    "                _weight[keys_list[i+2]].resize_(alpha,beta,3,3)\n",
    "                _weight[keys_list[i+3]].resize_(alpha+1)\n",
    "            elif i is 2:\n",
    "                _weight[keys_list[i+1]].resize_(alpha+1)\n",
    "                _weight[keys_list[i+3]].resize_(beta+1)\n",
    "                _weight[keys_list[i+2]].resize_(beta,gamma,3,3)\n",
    "                _weight[keys_list[i]].resize_(alpha,beta,3,3)\n",
    "            elif i is 4:\n",
    "                _weight[keys_list[i]].resize_(beta,gamma,3,3)\n",
    "                _weight[keys_list[i-2]].resize_(alpha,beta,3,3)\n",
    "                _weight[keys_list[i-1]].resize_(alpha+1)\n",
    "                _weight[keys_list[i+1]].resize_(beta+1)\n",
    "                _weight[keys_list[i+2]].resize_(gamma,upscale_factor ** 2,3,3)\n",
    "                _weight[keys_list[i+3]].resize_(gamma+1)\n",
    "            _model.load_state_dict(_weight)\n",
    "            _model=_model.cuda()\n",
    "            if retrain is True:\n",
    "                for k in range(0,epoch):\n",
    "                    _train(_model,k)\n",
    "            prnr=PSNR(_model)\n",
    "            print('conv:',i,' num:',j,' psnr:',prnr,' size:',temp_weight)\n",
    "            psnr_list.append(tuple([i,j,prnr,temp_weight]))\n",
    "    return psnr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pruning(_model,_weight,index,epoch=50):\n",
    "    \"\"\"\n",
    "    _model: 모델을 받는다.\n",
    "    _weight:weight값을 받는다.\n",
    "    index: pruning을 시행할 convolution 의 index 값을 받는다.\n",
    "    epoch: pruning후 retrain 할 횟수\n",
    "    \"\"\"\n",
    "    keys_list=list(_weight.keys())\n",
    "    temp=[]\n",
    "    for i in range(0,len(keys_list)-2,2):\n",
    "        temp.append(len(_weight[keys_list[i]]))\n",
    "    alpha,beta,gamma=temp\n",
    "    i=0\n",
    "    j=index[1]\n",
    "    if index[0] is 1:\n",
    "        i=0\n",
    "        alpha-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    elif index[0] is 2:\n",
    "        i=2\n",
    "        beta-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    elif index[0] is 3:\n",
    "        i=4\n",
    "        gamma-=1\n",
    "        modify(_model,alpha,beta,gamma)\n",
    "    if j>len(_weight[keys_list[i]]):\n",
    "        print(\"illegal pruning\")\n",
    "        return\n",
    "    weight_matrix=_weight[keys_list[i]]\n",
    "    bias_matrix=_weight[keys_list[i+1]]\n",
    "    if index[1] is 0:\n",
    "        _weight[keys_list[i]]=weight_matrix[1:len(_weight[keys_list[i]])]\n",
    "        _weight[keys_list[i+1]]=bias_matrix[1:len(_weight[keys_list[i]])+1]\n",
    "    elif j is len(model[keys_list[i]])-1:\n",
    "        _weight[keys_list[i]]=weight_matrix[0:len(_weight[keys_list[i]])-1]\n",
    "        _weight[keys_list[i+1]]=bias_matrix[0:len(_weight[keys_list[i]])]\n",
    "    else:\n",
    "        _weight[keys_list[i]]=torch.cat((weight_matrix[0:j],weight_matrix[j+1:len(_weight[keys_list[i]])]))\n",
    "        _weight[keys_list[i+1]]=torch.cat((bias_matrix[0:j],bias_matrix[j+1:len(_weight[keys_list[i]])+1]))\n",
    "    if i is 0:\n",
    "        _weight[keys_list[i+2]].resize_(alpha,beta,3,3)\n",
    "    elif i is 2:\n",
    "        \n",
    "        _weight[keys_list[i+2]].resize_(beta,gamma,3,3)\n",
    "    elif i is 4:\n",
    "        _weight[keys_list[i+2]].resize_(gamma,upscale_factor ** 2,3,3)\n",
    "    _model=_model.cuda()\n",
    "    for k in range(0,epoch):\n",
    "        _train(_model,k)\n",
    "    prnr=PSNR(_model)\n",
    "    print('conv:',index[0],' num:',j,'is pruning psnr:',prnr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Starting Calculate Pruning\n",
      "64 64 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py:514: UserWarning: src is not broadcastable to dst, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  own_state[name].copy_(param)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Epoch 0 Complete: Avg. Loss: 0.2204\n",
      "conv: 0  num: 0  psnr: 22.57898349758568  size: 2.926562786102295\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2178\n",
      "conv: 0  num: 1  psnr: 22.23948825974483  size: 3.5600385665893555\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.2154\n",
      "conv: 0  num: 2  psnr: 22.01875357781445  size: 2.7003331184387207\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1708\n",
      "conv: 0  num: 3  psnr: 22.75825348331718  size: 3.595670461654663\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1823\n",
      "conv: 0  num: 4  psnr: 22.052491650819057  size: 3.4622962474823\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1912\n",
      "conv: 0  num: 5  psnr: 22.100526723724716  size: 3.3184256553649902\n",
      "===> Epoch 0 Complete: Avg. Loss: 0.1880\n"
     ]
    }
   ],
   "source": [
    "pruning=100\n",
    "for _ in range(1,pruning):\n",
    "    lista=cal_pruning(train,model,epoch=10)\n",
    "    indexa=rank(lista)\n",
    "    _pruning(train,model,indexa,epoch=150)\n",
    "    print(_,\" 번째 pruning 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
